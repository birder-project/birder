{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a5c882-4366-4c97-80db-5fd20bc70e47",
   "metadata": {},
   "source": [
    "# Birder - Getting Started\n",
    "\n",
    "In this notebook we will explore some of the API's provided by Birder.\n",
    "\n",
    "Before we start, if you're running in Colab, make sure to install Birder first.\n",
    "Numpy 2.0 and above are not yet supported on Colab, so you might have to downgrade as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc252ff2-36e7-4b25-bc0f-7b11394ad3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Colab\n",
    "# !pip install birder\n",
    "\n",
    "# When running in a cloned repository (instead of pip installation)\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7523e77-b876-4b2d-8221-ae7a447cc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import birder\n",
    "import torch\n",
    "from birder.inference.classification import infer_image\n",
    "from birder.results.gui import show_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560c1da-3587-4ab4-8301-e4c78ee590e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "birder.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cbcd6-3615-47f4-894f-c455fb6f1aa9",
   "metadata": {},
   "source": [
    "## Exploring Models\n",
    "\n",
    "Birder uses a systematic naming convention that helps you identify the key characteristics of each model. The naming pattern includes:\n",
    "\n",
    "* Architecture prefix (e.g., xcit, resnext, mobilenet)\n",
    "* Optional: Net parameter value indicating model configuration\n",
    "* Optional: Training indicators tags (intermediate, mim)\n",
    "* Optional: Geographical tags indicating data source (il-common, eu-all)\n",
    "* Optional: Optimization tags (quantized, reparameterized)\n",
    "* Optional: Epoch number\n",
    "\n",
    "We can list all pretrained models according to any filter (or without). The filter uses glob-style pattern matching, where '*' matches any sequence of characters.\n",
    "\n",
    "Let's look at all models that were trained on the *il-common* dataset and load one of them.\n",
    "The pattern below will match any XCiT model trained on the *il-common* dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64152f-66e1-42b6-af68-ccc14ce5e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "birder.list_pretrained_models(\"xcit*il-common*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc25afe-3160-4322-b7bd-b20f17804a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(net, model_info) = birder.load_pretrained_model(\"xcit_nano12_p16_il-common\", inference=True)\n",
    "\n",
    "# Get the image size the model was trained on\n",
    "size = birder.get_size_from_signature(model_info.signature)\n",
    "\n",
    "# Create an inference transform\n",
    "transform = birder.classification_transform(size, model_info.rgb_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912bc12-4e0f-4fb2-89f3-f4b5a75871e3",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now we shall fetch an example image (of a Eurasian teal) and try to classify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b9a14-9367-42f5-9d11-fade9d82e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it's a first run, create the data dir\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada0c81-82cf-4d5f-a460-790155426bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/example.jpeg\"\n",
    "birder.common.cli.download_file(\"https://huggingface.co/spaces/birder-project/birder-image-classification/resolve/main/Eurasian%20teal.jpeg\", image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d9b10-49ee-4608-a16a-8e1ad47fb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "(out, _) = infer_image(net, image_path, transform)\n",
    "show_top_k(image_path, out.squeeze(), model_info.class_to_idx, \"Eurasian teal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b380d7-ef2d-494c-b22e-973bef82a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model failed to classify it correctly, this is probably because the object is small\n",
    "# and we are using a low resolution compact model.\n",
    "#\n",
    "# We will try again using an aggressive center crop.\n",
    "transform = birder.classification_transform(size, model_info.rgb_stats, center_crop=0.5)\n",
    "(out, _) = infer_image(net, image_path, transform)\n",
    "show_top_k(image_path, out.squeeze(), model_info.class_to_idx, \"Eurasian teal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810be14-6917-4c22-ad6a-d4d3047f5756",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "We shall now fine-tune the model on an example dataset.\n",
    "\n",
    "For this example we will use the Caltech-UCSD Birds-200-2011 dataset - <https://authors.library.caltech.edu/records/cvm3y-5hh21>.\n",
    "\n",
    "It has about ~12K images of 200 species.\n",
    "\n",
    "We will first do simple linear probing and later a full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bf57b-e36c-471b-856e-864c293327e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birder.datahub.classification import CUB_200_2011\n",
    "from birder.scripts import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ee296-2684-42ba-b148-02389527d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CUB_200_2011(download=True, split=\"training\")  # Will download all splits\n",
    "validation_dataset = CUB_200_2011(split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb8f32-7eab-4d17-826a-64a5a0e93b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing\n",
    "args = train.args_from_dict(\n",
    "    network=\"xcit_nano12_p16\",\n",
    "    pretrained=True,  # Implies \"reset head\"\n",
    "    freeze_body=True,\n",
    "    tag=\"il-common\",\n",
    "    num_workers=2,\n",
    "    lr=0.1,\n",
    "    lr_scheduler=\"cosine\",\n",
    "    epochs=5,\n",
    "    size=256,\n",
    "    data_path=training_dataset.root,\n",
    "    val_path=validation_dataset.root,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7fed40-b729-4aaa-8fdb-845dc6ad9f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc4a55-4b3b-4938-889b-fc286ca57c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full fine-tuning for 10 epochs\n",
    "args = train.args_from_dict(\n",
    "    network=\"xcit_nano12_p16\",\n",
    "    tag=\"il-common\",\n",
    "    num_workers=2,\n",
    "    opt=\"adamw\",\n",
    "    lr=0.0001,\n",
    "    lr_scheduler=\"cosine\",\n",
    "    lr_cosine_min=1e-7,\n",
    "    epochs=15,\n",
    "    resume_epoch=5,\n",
    "    size=256,\n",
    "    wd=0.05,\n",
    "    norm_wd=0,\n",
    "    grad_accum_steps=2,\n",
    "    smoothing_alpha=0.1,\n",
    "    mixup_alpha=0.2,\n",
    "    cutmix=True,\n",
    "    aug_level=4,\n",
    "    clip_grad_norm=1,\n",
    "    fast_matmul=True,\n",
    "    # compile=True,\n",
    "    data_path=training_dataset.root,\n",
    "    val_path=validation_dataset.root,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b91b36-32f1-4e47-a801-7c78c80e1771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa82d2-92af-4444-bc86-b9089c1d5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe60db8-5bf7-45fc-833d-072b880d564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the training\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834e3ee-e02e-4971-aeef-1848b12aca89",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443af4f-0184-4aa0-b48a-3cb2ccfe7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from birder.common.fs_ops import load_model\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ae900-1cd0-484a-a0e3-1d0604747aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "(net, model_info) = load_model(\n",
    "    device, \"xcit_nano12_p16\", tag=\"il-common\", epoch=15, inference=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f970b-fbdc-4ec4-b4be-361333fb29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = birder.classification_transform(size, model_info.rgb_stats)\n",
    "dataset = CUB_200_2011(split=\"validation\", transform=transform)\n",
    "inference_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05380227-03be-4ef4-8376-465b9222854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = birder.evaluate_classification(device, net, inference_loader, model_info.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ca0e1-95c5-4b9b-800b-b4b3dd68d8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.log_short_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db576c0d-c0c7-40e9-98c9-dd3d6e6ce110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can examine a detailed per-class report\n",
    "report_df = results.detailed_report()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff187dc6-3e51-47d6-a412-9a066ebd22de",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2255781-eadd-4356-abe7-8a02069f7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birder.results.gui import ProbabilityHistogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c4337-fe3e-47cb-a70c-796caae13975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 5 lowest scoring classes\n",
    "results.pretty_print(sort_by=\"f1-score\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf16dfe-ce26-4438-b29b-55051ce91503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the top most confused pairs\n",
    "results.most_confused()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12991147-9f79-4985-a4b9-c9d008d5e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(torch.device(\"cpu\"))\n",
    "\n",
    "# Examine the most confused classes\n",
    "confusion_sample = results.mistakes.filter(pl.col(\"label_name\") == results.most_confused()[\"actual\"][0])[0]\n",
    "image_path = confusion_sample[\"sample\"].item()\n",
    "(out, _) = infer_image(net, image_path, transform)\n",
    "show_top_k(image_path, out.squeeze(), model_info.class_to_idx, confusion_sample[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4307ee-2899-47a8-99a1-880d334cc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_sample = results.mistakes.filter(pl.col(\"label_name\") == results.most_confused()[\"predicted\"][0])[0]\n",
    "image_path = confusion_sample[\"sample\"].item()\n",
    "(out, _) = infer_image(net, image_path, transform)\n",
    "show_top_k(image_path, out.squeeze(), model_info.class_to_idx, confusion_sample[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9771bea-ae03-4b70-aff9-e79384587d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbabilityHistogram(results).show(results.most_confused()[\"actual\"][0], results.most_confused()[\"predicted\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birder",
   "language": "python",
   "name": "birder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
