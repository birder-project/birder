---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.18.1
  kernelspec:
    display_name: birder
    language: python
    name: birder
---

```{python}
import sys

import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
```

```{python}
# %cd ..
```

```{python}
from birder.common import fs_ops
from birder.common import lib
from birder.net.base import pos_embedding_sin_cos_2d
from birder.net.rope_vit import RoPE
from birder.net.rope_vit import rotate_half
from birder.net.rope_vit import rotate_half_interleaved
```

```{python}
device = torch.device("cpu")
```

## Simple ViT

```{python}
pos_embedding = pos_embedding_sin_cos_2d(14, 14, 768, 0)
plt.matshow(pos_embedding.numpy())
```

```{python}
pos_embedding = pos_embedding_sin_cos_2d(14, 14, 768, 0)
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.numpy())
```

## ViT

```{python}
(net, model_info) = fs_ops.load_model(device, "vit_reg4_b16", path="models/vit_reg4_b16_mim_300.pt", inference=True)
# (net, model_info) = fs_ops.load_model(
#     device, "vit_l16", path="models/vit_l16_mim_362.pt", inference=True
# )
# size = lib.get_size_from_signature(signature)
# size = (size[0] // net.patch_size, size[1] // net.patch_size)
```

```{python}
num_prefix_tokens = net.num_special_tokens
pos_embedding = net.pos_embedding[:, num_prefix_tokens:]
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.numpy())
```

```{python}
net.adjust_size((256, 256))
```

```{python}
pos_embedding = net.pos_embedding[:, num_prefix_tokens:]
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

## Hiera

```{python}
(net, model_info) = fs_ops.load_model(
    device, "hiera_abswin_base", path="models/hiera_abswin_base_mim.pt", inference=True
)
```

```{python}
pos_embedding = net._get_pos_embed()
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.numpy())
```

```{python}
net.adjust_size((256, 256))
```

```{python}
pos_embedding = net._get_pos_embed()
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

## CaiT

```{python}
(net, model_info) = fs_ops.load_model(device, "cait_xxs24", path="models/cait_xxs24_il-common.pt", inference=True)
```

```{python}
pos_embedding = net.pos_embed
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.numpy())
```

```{python}
net.adjust_size((320, 320))
```

```{python}
pos_embedding = net.pos_embed
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

## Swin Transformer v2

```{python}
(net, model_info) = fs_ops.load_model(
    device,
    "swin_transformer_v2_s",
    path="models/swin_transformer_v2_s_intermediate-arabian-peninsula.pt",
    inference=True,
)
```

```{python}
net.body[0][0].attn.relative_coords_table.size(), net.body[0][0].attn.relative_position_index.size()
```

```{python}
pos_embedding = net.body[0][0].attn.relative_coords_table.reshape(1, -1, 2)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
pos_embedding = net.body[1][1].attn.relative_coords_table.reshape(1, -1, 2)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
pos_embedding = net.body[3][2].attn.relative_coords_table.reshape(1, -1, 2)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
net.adjust_size((256, 256))
```

```{python}
pos_embedding = net.body[0][0].attn.relative_coords_table.reshape(1, -1, 2)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

## iFormer

```{python}
(net, model_info) = fs_ops.load_model(device, "iformer_s", path="models/iformer_s_arabian-peninsula.pt", inference=True)
```

```{python}
pos_embedding = net.body[1].pos_embed.reshape(1, -1, 96)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
net.adjust_size((448, 448))
```

```{python}
pos_embedding = net.body[1].pos_embed.reshape(1, -1, 96)
pos_embedding.size()
```

```{python}
similarity = pos_embedding.squeeze() @ pos_embedding.squeeze().T
plt.matshow(similarity.detach().numpy())
```

## RoPE

```{python}
rope = RoPE(768, temperature=100.0, grid_size=(16, 16), grid_indexing="ij", grid_offset=0)
```

```{python}
pos_embedding = rope.pos_embed
(sin_emb, cos_emb) = pos_embedding.tensor_split(2, -1)
```

```{python}
sin_emb.size(), cos_emb.size()
```

```{python}
plt.matshow(cos_emb.detach().numpy())
```

```{python}
plt.matshow(rotate_half(sin_emb).detach().numpy())
```

```{python}
plt.matshow(cos_emb.detach().numpy() + rotate_half(sin_emb).detach().numpy())
```

```{python}
similarity = rotate_half(sin_emb).squeeze() @ rotate_half(sin_emb).squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
similarity = cos_emb.squeeze() @ cos_emb.squeeze().T
plt.matshow(similarity.detach().numpy())
```

```{python}
plt.matshow(rotate_half_interleaved(sin_emb).detach().numpy())
```

```{python}
plt.matshow(cos_emb.detach().numpy() + rotate_half_interleaved(sin_emb).detach().numpy())
```

```{python}
similarity = rotate_half_interleaved(sin_emb).squeeze() @ rotate_half_interleaved(sin_emb).squeeze().T
plt.matshow(similarity.detach().numpy())
```
