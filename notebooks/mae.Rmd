---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: birder
    language: python
    name: birder
---

```{python}
import logging
import sys

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
```

```{python}
sys.path.append("..")
```

```{python}
from birder.common import cli
from birder.common.lib import get_label_from_path
from birder.conf import settings
from birder.core.transforms.classification import get_rgb_values, inference_preset
from birder.model_registry import registry
```

```{python}
plt.rcParams["figure.figsize"] = [24, 24]
```

```{python}
# %cd ..
```

```{python}
def show_image(image, title=""):
    mean = np.array((0.5189, 0.5255, 0.4845))
    std = np.array((0.2124, 0.2083, 0.2555))
    # image is [H, W, 3]
    assert image.shape[2] == 3
    plt.imshow(torch.clip((image * std + mean) * 255, 0, 255).int())
    plt.title(title, fontsize=16)
    plt.axis("off")
```

```{python}
network = "mae_vit"
encoder = "vitreg4_b16"
encoder_param = None
size = 224

# network = "fcmae"
# encoder = "convnext_v2"
# encoder_param = 5
# size = 224

# network = "simmim"
# encoder = "swin_transformer_v2_s"
# encoder_param = None
# size = 192

# network = "simmim"
# encoder = "maxvit_t"
# encoder_param = None
# size = 192

epoch_start = 1
epoch_end = 400

image = "data/validation/Bluethroat/000013.jpeg"
# image = "data/training/African crake/000005.jpeg"
# image = "data/training/African swamphen/000001.jpeg"
# image = "data/validation/Barn owl/000013.jpeg"
# image = "data/validation/Zitting cisticola/000025.jpeg"
# image = "data/validation/Great egret/000031.jpeg"
img = Image.open(image)
```

```{python}
logging.disable(logging.INFO)
device = torch.device("cpu")
for e in range(epoch_start, epoch_end + 1):
    try:
        (net, _, _, _) = cli.load_pretrain_checkpoint(
            device,
            network,
            net_param=None,
            encoder=encoder,
            encoder_param=encoder_param,
            epoch=e,
        )
        net.eval()

    except FileNotFoundError:
        continue

    transform = inference_preset((size, size), 1.0, get_rgb_values("calculated"))
    input_tensor = transform(img).unsqueeze(dim=0).to(device)

    torch.manual_seed(0)
    output = net(input_tensor)

    loss = output["loss"]
    pred = output["pred"]
    mask = output["mask"]

    y = net.unpatchify(pred)

    y = torch.einsum("nchw->nhwc", y).detach().cpu()

    # visualize the mask
    mask = mask.detach()
    mask = mask.unsqueeze(-1).repeat(1, 1, net.patch_size**2 * 3)
    mask = net.unpatchify(mask)  # 1 is removing, 0 is keeping
    mask = torch.einsum("nchw->nhwc", mask).detach().cpu()

    x = torch.einsum("nchw->nhwc", input_tensor).squeeze(0)

    # Masked image
    im_masked = x * (1 - mask)

    # MAE reconstruction pasted with visible patches
    im_paste = x * (1 - mask) + y * mask

    plt.subplot(1, 4, 1)
    show_image(x, "Original")

    plt.subplot(1, 4, 2)
    show_image(im_masked[0], "Masked")

    plt.subplot(1, 4, 3)
    show_image(y[0], "Reconstruction")

    plt.subplot(1, 4, 4)
    show_image(im_paste[0], "Reconstruction + Visible")

    plt.show()

logging.disable(logging.NOTSET)
```

```{python}

```
